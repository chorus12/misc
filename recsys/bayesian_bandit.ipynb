{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57049808-85f1-4b4e-a313-bc97d1f601d9",
   "metadata": {},
   "source": [
    "# Using Bayesian and Grad policy approach to get most possible rewards from bandit machines  \n",
    "from https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83dd31fc-0a29-41ff-92be-2b1346dc9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8197192-0a79-4106-8b16-34b713fb43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 2000\n",
    "BANDIT_PROBABILITIES = [0.1,0.5,0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed26fb-baca-4913-b63b-d60760200e9a",
   "metadata": {},
   "source": [
    "## Bayesian implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f7774ec-74f0-4431-a67a-7d3448283dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditBernoulli(object):\n",
    "    '''\n",
    "    class to simulate a bandit with given probability\n",
    "    '''\n",
    "    def __init__(self, p):\n",
    "        '''\n",
    "        Input: p - true probability for a bandit\n",
    "        Also sets the following properties:\n",
    "        N - number of trials run so far\n",
    "        a, b - params of Beta distribution set to 1 and 1 for uniform\n",
    "        '''\n",
    "        self.p = p\n",
    "        self.a , self.b = 1, 1\n",
    "        self.N = 0\n",
    "        \n",
    "    def pull(self):\n",
    "        # get a real value from bandit\n",
    "        return np.random.random() <= self.p\n",
    "\n",
    "    def get_pdf(self,x):\n",
    "        return beta.pdf(x,self.a,self.b)\n",
    "\n",
    "    def sample(self):\n",
    "        # Get an estimation of p from Beta distribution\n",
    "        return beta.rvs(self.a, self.b)\n",
    "    \n",
    "    def update(self, x):\n",
    "        #update a and b after a bandit pull\n",
    "        self.N += 1\n",
    "        self.a += x\n",
    "        self.b += 1 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fc1393d-d540-474f-ade9-22d513d67116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(bandits, trial):\n",
    "    # plot all bandit distributions on the graph\n",
    "    x = np.linspace(0, 1, 200)\n",
    "    for b in bandits:\n",
    "        y = b.get_pdf(x)\n",
    "        plt.plot(x, y, label=f\"real p: {b.p:.4f}, win rate = {b.a - 1}/{b.N}\")\n",
    "    plt.title(f\"Bandit distributions after {trial} trials\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ff934bb-fe69-4678-995e-3442bd0354e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(class_name, plot_graphs=False):\n",
    "    # class_name - what class to create\n",
    "    bandits = [class_name(p) for p in BANDIT_PROBABILITIES] # instantiate bandits\n",
    "\n",
    "    sample_points = [5,10,20,50,100,200,500,1000,1500,1999]\n",
    "    \n",
    "    rewards = np.zeros(NUM_TRIALS)\n",
    "    \n",
    "    for i in range(NUM_TRIALS):\n",
    "        # Thompson sampling - take the bandit with the highest prob to win\n",
    "        j = np.argmax([b.sample() for b in bandits])\n",
    "\n",
    "        # plot the posteriors\n",
    "        if (i in sample_points)and(plot_graphs):\n",
    "            plot(bandits, i)\n",
    "\n",
    "        # pull the arm for the bandit with the largest sample\n",
    "        x = bandits[j].pull()\n",
    "\n",
    "        # update rewards\n",
    "        rewards[i] = x\n",
    "\n",
    "        # update the distribution for the bandit whose arm we just pulled\n",
    "        bandits[j].update(x)\n",
    "\n",
    "    # print total reward\n",
    "    print(\"total reward earned:\", rewards.sum())\n",
    "    print(\"overall win rate:\", rewards.sum() / NUM_TRIALS)\n",
    "    print(\"num times selected each bandit:\", [b.N for b in bandits])\n",
    "    return rewards.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "356fe7c3-a34e-4bb9-a079-b553d5c3d872",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward earned: 1166.0\n",
      "overall win rate: 0.583\n",
      "num times selected each bandit: [10, 133, 1857]\n",
      "total reward earned: 1199.0\n",
      "overall win rate: 0.5995\n",
      "num times selected each bandit: [8, 85, 1907]\n",
      "total reward earned: 1220.0\n",
      "overall win rate: 0.61\n",
      "num times selected each bandit: [12, 31, 1957]\n",
      "total reward earned: 1181.0\n",
      "overall win rate: 0.5905\n",
      "num times selected each bandit: [9, 72, 1919]\n",
      "total reward earned: 1190.0\n",
      "overall win rate: 0.595\n",
      "num times selected each bandit: [7, 352, 1641]\n",
      "total reward earned: 1196.0\n",
      "overall win rate: 0.598\n",
      "num times selected each bandit: [19, 69, 1912]\n",
      "total reward earned: 1187.0\n",
      "overall win rate: 0.5935\n",
      "num times selected each bandit: [8, 10, 1982]\n",
      "total reward earned: 1205.0\n",
      "overall win rate: 0.6025\n",
      "num times selected each bandit: [9, 82, 1909]\n",
      "total reward earned: 1171.0\n",
      "overall win rate: 0.5855\n",
      "num times selected each bandit: [7, 489, 1504]\n",
      "total reward earned: 1219.0\n",
      "overall win rate: 0.6095\n",
      "num times selected each bandit: [7, 57, 1936]\n",
      "total reward earned: 1173.0\n",
      "overall win rate: 0.5865\n",
      "num times selected each bandit: [18, 244, 1738]\n",
      "total reward earned: 1175.0\n",
      "overall win rate: 0.5875\n",
      "num times selected each bandit: [6, 59, 1935]\n",
      "total reward earned: 1162.0\n",
      "overall win rate: 0.581\n",
      "num times selected each bandit: [8, 41, 1951]\n",
      "total reward earned: 1186.0\n",
      "overall win rate: 0.593\n",
      "num times selected each bandit: [7, 49, 1944]\n",
      "total reward earned: 1171.0\n",
      "overall win rate: 0.5855\n",
      "num times selected each bandit: [7, 138, 1855]\n",
      "total reward earned: 1112.0\n",
      "overall win rate: 0.556\n",
      "num times selected each bandit: [8, 374, 1618]\n",
      "total reward earned: 1168.0\n",
      "overall win rate: 0.584\n",
      "num times selected each bandit: [8, 90, 1902]\n",
      "total reward earned: 1209.0\n",
      "overall win rate: 0.6045\n",
      "num times selected each bandit: [6, 125, 1869]\n",
      "total reward earned: 1187.0\n",
      "overall win rate: 0.5935\n",
      "num times selected each bandit: [9, 18, 1973]\n",
      "total reward earned: 1183.0\n",
      "overall win rate: 0.5915\n",
      "num times selected each bandit: [7, 78, 1915]\n",
      "total reward earned: 1219.0\n",
      "overall win rate: 0.6095\n",
      "num times selected each bandit: [15, 22, 1963]\n",
      "total reward earned: 1165.0\n",
      "overall win rate: 0.5825\n",
      "num times selected each bandit: [14, 111, 1875]\n",
      "total reward earned: 1191.0\n",
      "overall win rate: 0.5955\n",
      "num times selected each bandit: [8, 175, 1817]\n",
      "total reward earned: 1189.0\n",
      "overall win rate: 0.5945\n",
      "num times selected each bandit: [13, 96, 1891]\n",
      "total reward earned: 1219.0\n",
      "overall win rate: 0.6095\n",
      "num times selected each bandit: [7, 65, 1928]\n",
      "total reward earned: 1156.0\n",
      "overall win rate: 0.578\n",
      "num times selected each bandit: [10, 233, 1757]\n",
      "total reward earned: 1182.0\n",
      "overall win rate: 0.591\n",
      "num times selected each bandit: [7, 109, 1884]\n",
      "total reward earned: 1205.0\n",
      "overall win rate: 0.6025\n",
      "num times selected each bandit: [10, 86, 1904]\n",
      "total reward earned: 1190.0\n",
      "overall win rate: 0.595\n",
      "num times selected each bandit: [7, 113, 1880]\n",
      "total reward earned: 1158.0\n",
      "overall win rate: 0.579\n",
      "num times selected each bandit: [7, 243, 1750]\n",
      "total reward earned: 1199.0\n",
      "overall win rate: 0.5995\n",
      "num times selected each bandit: [20, 102, 1878]\n",
      "total reward earned: 1193.0\n",
      "overall win rate: 0.5965\n",
      "num times selected each bandit: [7, 148, 1845]\n",
      "total reward earned: 1187.0\n",
      "overall win rate: 0.5935\n",
      "num times selected each bandit: [9, 172, 1819]\n",
      "total reward earned: 1165.0\n",
      "overall win rate: 0.5825\n",
      "num times selected each bandit: [21, 53, 1926]\n",
      "total reward earned: 1185.0\n",
      "overall win rate: 0.5925\n",
      "num times selected each bandit: [7, 69, 1924]\n",
      "total reward earned: 1204.0\n",
      "overall win rate: 0.602\n",
      "num times selected each bandit: [7, 349, 1644]\n",
      "total reward earned: 1196.0\n",
      "overall win rate: 0.598\n",
      "num times selected each bandit: [9, 256, 1735]\n",
      "total reward earned: 1193.0\n",
      "overall win rate: 0.5965\n",
      "num times selected each bandit: [6, 159, 1835]\n",
      "total reward earned: 1159.0\n",
      "overall win rate: 0.5795\n",
      "num times selected each bandit: [11, 128, 1861]\n",
      "total reward earned: 1218.0\n",
      "overall win rate: 0.609\n",
      "num times selected each bandit: [19, 38, 1943]\n",
      "total reward earned: 1171.0\n",
      "overall win rate: 0.5855\n",
      "num times selected each bandit: [10, 249, 1741]\n",
      "total reward earned: 1152.0\n",
      "overall win rate: 0.576\n",
      "num times selected each bandit: [12, 371, 1617]\n",
      "total reward earned: 1148.0\n",
      "overall win rate: 0.574\n",
      "num times selected each bandit: [13, 219, 1768]\n",
      "total reward earned: 1194.0\n",
      "overall win rate: 0.597\n",
      "num times selected each bandit: [6, 137, 1857]\n",
      "total reward earned: 1201.0\n",
      "overall win rate: 0.6005\n",
      "num times selected each bandit: [9, 166, 1825]\n",
      "total reward earned: 1082.0\n",
      "overall win rate: 0.541\n",
      "num times selected each bandit: [15, 618, 1367]\n",
      "total reward earned: 1166.0\n",
      "overall win rate: 0.583\n",
      "num times selected each bandit: [16, 192, 1792]\n",
      "total reward earned: 1194.0\n",
      "overall win rate: 0.597\n",
      "num times selected each bandit: [8, 51, 1941]\n",
      "total reward earned: 1194.0\n",
      "overall win rate: 0.597\n",
      "num times selected each bandit: [9, 263, 1728]\n",
      "total reward earned: 1203.0\n",
      "overall win rate: 0.6015\n",
      "num times selected each bandit: [7, 223, 1770]\n"
     ]
    }
   ],
   "source": [
    "# run experiment 50 times\n",
    "bayes_reward = np.array([experiment(BanditBernoulli) for k in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55c3a1d5-9e77-4be1-b83d-05c5c4094642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(bayes_reward, kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb53c59-f5db-4299-b264-a9312069a53d",
   "metadata": {},
   "source": [
    "##  Grad policy updater implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cf2cbd6f-f7b4-4da9-baf6-69ef70fe8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradBandit(object):\n",
    "    # class to model a bandit with Grad Uphill Algorythm\n",
    "    def __init__(self, p, alpha=0.1):\n",
    "        self.p = p\n",
    "        self.N = 0 # how many times the bandit was used\n",
    "        self.H = 0 # H - the preference towards this bandit\n",
    "        self.alpha = alpha # learning rate for the update of preference H\n",
    "        \n",
    "    def pull(self):\n",
    "        # get a real value from bandit\n",
    "        self.N += 1\n",
    "        return np.random.random() <= self.p\n",
    "\n",
    "    def update(self, delta):\n",
    "        # update a preference\n",
    "        self.H += self.alpha*delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "37eef125-fa27-4ec9-9785-696336d256ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradBanditUpdater(object):\n",
    "    def __init__(self, grad_bandits):\n",
    "        self.grad_bandits = grad_bandits # list with bandits\n",
    "        self.NB = len(grad_bandits) # number of bandits \n",
    "        self.probs = [1/len(self.grad_bandits)]*self.NB # initial probs to select bandits\n",
    "        self.reward = 0 # cumulative reward for updater\n",
    "        self.running_n = 0 # number pull iterations\n",
    "    def update_probs(self):\n",
    "        # apply softmax to bandits and update probs for updater\n",
    "        softmax_denominator = np.sum([np.exp(b.H) for b in self.grad_bandits])\n",
    "        for i,b in enumerate(self.grad_bandits):\n",
    "            self.probs[i] = np.exp(b.H)/softmax_denominator\n",
    "    def get_pull_bandit(self):\n",
    "        # select a bandit to pull from \n",
    "        return np.random.choice(list(range(self.NB)),1,p=self.probs)[0]\n",
    "    def pull_bandit(self, i):\n",
    "        # actuall pull a bandit number i from the self.grad_bandits\n",
    "        self.running_n +=1\n",
    "        return np.random.random() <= self.grad_bandits[i].p\n",
    "    def make_iteration(self):\n",
    "        # main routine - makes a selection and updates all data\n",
    "        # make a selection of bandit\n",
    "        selected_bandit = self.get_pull_bandit()\n",
    "        # pull a bandit\n",
    "        iteration_reward = self.pull_bandit(selected_bandit)\n",
    "        self.reward += iteration_reward # update reward\n",
    "        current_mean_reward = self.reward/self.running_n # update mean reward\n",
    "        # update preference estimation\n",
    "        for i in range(self.NB):\n",
    "            if i == selected_bandit:\n",
    "                delta = (iteration_reward - current_mean_reward)*(1 - self.probs[i])\n",
    "            else:\n",
    "                delta = -(iteration_reward - current_mean_reward)*self.probs[i]\n",
    "            self.grad_bandits[i].update(delta)\n",
    "        # update probs via softmax\n",
    "        self.update_probs()\n",
    "        # and we are done\n",
    "        return self.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e0a5b015-285f-48dc-80a9-62cb17d80ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_bandits = [GradBandit(p) for p in BANDIT_PROBABILITIES]\n",
    "gb_updater = GradBanditUpdater(grad_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "de338f6c-d760-4e22-8512-d4bd59ea126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_grad_bandits():\n",
    "    grad_bandits = [GradBandit(p) for p in BANDIT_PROBABILITIES]\n",
    "    gb_updater = GradBanditUpdater(grad_bandits)\n",
    "    trial_results =[]\n",
    "    for i in range(NUM_TRIALS):\n",
    "        trial_results.append(gb_updater.make_iteration())\n",
    "    return gb_updater, trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6338665-1e8e-465b-9e7f-865f43cf9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 50 experiments\n",
    "gb_rewards = []\n",
    "for i in tqdm(range(50)):\n",
    "    gb_updater, trial_results = experiment_grad_bandits()\n",
    "    gb_rewards.append(gb_updater.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b66bca-3e5f-4ed2-b5ea-91e002d786c9",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "231a889f-a376-4f43-a653-14ed51397122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "668c1f35-c2ae-403e-b8ff-7f1054b5d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=6.987149486641803, pvalue=3.4162541586138974e-10)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they are different\n",
    "st.ttest_ind(bayes_reward, gb_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "18063d9a-4332-450d-87d1-1290ecfbb4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 - 1156 Grad policy updater \n",
      "1175 - 1190 Bayesian updater\n"
     ]
    }
   ],
   "source": [
    "gb_reward_interval = st.t.interval(alpha=0.95, df=len(gb_rewards)-1, loc=np.mean(gb_rewards), scale=st.sem(gb_rewards))\n",
    "bayes_reward_interval =  st.t.interval(alpha=0.95, df=len(bayes_reward)-1, loc=np.mean(bayes_reward), scale=st.sem(bayes_reward)) \n",
    "\n",
    "print(f\"{gb_reward_interval[0]:.0f} - {gb_reward_interval[1]:.0f} Grad policy updater \")\n",
    "print(f\"{bayes_reward_interval[0]:.0f} - {bayes_reward_interval[1]:.0f} Bayesian updater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8aa24b-0b4f-4019-b982-8cda5d64bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(bayes_reward)-np.mean(gb_rewards))/np.mean(gb_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e24a4d-89d8-4d5b-a433-a903a982c744",
   "metadata": {},
   "source": [
    "## Debug zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ea6665c9-4215-4b8a-9849-2ab0ec05bef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_updater.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8fcdb793-9d48-4dae-ae17-995182af7667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_updater.make_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f057af38-5446-421c-aff7-b0ec945bea84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_updater.get_pull_bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4d4c5f0d-e18c-4452-9fc5-b252d96e2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_bandits[0].H = 110 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0b687a4b-2663-46b8-9aaa-02f4ce2cc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_bandits[2].H = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a2136796-23c0-47bc-b7cd-ebafc567eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_updater.update_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "37ad9ab8-f791-46b3-afcc-573adddb0447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26892959203422073, 0.3796829301340696, 0.3513874778317097]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_updater.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "33a1c0de-c21a-4e32-af13-6cc52101dc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_updater.grad_bandits[0].H"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
